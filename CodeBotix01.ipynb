{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGKnVAHejmlO"
   },
   "source": [
    "# Sigma: CodeBotix Data Consolidation\n",
    "\n",
    "#### Steps Taken\n",
    "1. Corrected mispalced columns in '2 Day learning surveys 2024-2025 American center.xlsx' Sheet 2\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5242,
     "status": "ok",
     "timestamp": 1757930603299,
     "user": {
      "displayName": "Teja Meruva",
      "userId": "00989741806545621269"
     },
     "user_tz": -330
    },
    "id": "BaYvCd75jjmS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nh-oBU8u3A5"
   },
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1757930606899,
     "user": {
      "displayName": "Teja Meruva",
      "userId": "00989741806545621269"
     },
     "user_tz": -330
    },
    "id": "gy7oGpYHu40B"
   },
   "outputs": [],
   "source": [
    "def InList(elem, l:list) -> bool:\n",
    "  for item in l:\n",
    "    if (elem.lower() in item.lower()) or (item.lower() in elem.lower()):\n",
    "      return True\n",
    "      break\n",
    "  return False\n",
    "\n",
    "def columnLike(X, cols: list, singleOp=True) -> str:\n",
    "  if not isinstance(X, list): X = [X]\n",
    "  op = []\n",
    "  for xi in X:\n",
    "    for item in cols:\n",
    "      if ((xi.lower().strip() in item.lower().strip()) or (item.lower().strip() in xi.lower().strip())) and ('unnamed' not in item.lower().strip()):\n",
    "        op.append(item)\n",
    "  if len(op) == 0: return None\n",
    "  if (len(op) == 1) or singleOp: op = op[0]\n",
    "  return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtmCb00nkjiA"
   },
   "source": [
    "#### Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1404,
     "status": "ok",
     "timestamp": 1757930608304,
     "user": {
      "displayName": "Teja Meruva",
      "userId": "00989741806545621269"
     },
     "user_tz": -330
    },
    "id": "LUpwJqULki38"
   },
   "outputs": [],
   "source": [
    "dataSets = []\n",
    "\n",
    "dataSets.append(pd.read_excel('data/1 hour Online intro to Robotics workshop-pilot.xlsx', sheet_name=0)) #0, 2, 3, 5, 9, 11\n",
    "dataSets.append(pd.read_excel('data/1 hour Online intro to Robotics workshop-pilot.xlsx', sheet_name=1))\n",
    "dataSets.append(pd.read_excel('data/10 day Summercamp Anna library Feedback .xlsx', sheet_name=0))\n",
    "dataSets.append(pd.read_excel('data/2 Day learning surveys 2024-2025 American center.xlsx', sheet_name=0))\n",
    "dataSets.append(pd.read_excel('data/2 Day learning surveys 2024-2025 American center.xlsx', sheet_name=1))\n",
    "dataSets.append(pd.read_excel('data/3 days  Robotics Trial Workshop -St. Patrick\\'s School 2024.xlsx', sheet_name=0))\n",
    "dataSets.append(pd.read_excel('data/3 days  Robotics Trial Workshop -St. Patrick\\'s School 2024.xlsx', sheet_name=1))\n",
    "dataSets.append(pd.read_excel('data/3 days  Robotics Trial Workshop -St. Patrick\\'s School 2024.xlsx', sheet_name=2))\n",
    "dataSets.append(pd.read_excel('data/3 days  Robotics Trial Workshop -St. Patrick\\'s School 2024.xlsx', sheet_name=3))\n",
    "dataSets.append(pd.read_excel('data/3 hour 2023-2024 Robotics workshop.xlsx', sheet_name=0))\n",
    "dataSets.append(pd.read_excel('data/3 hour 2023-2024 Robotics workshop.xlsx', sheet_name=1))\n",
    "dataSets.append(pd.read_excel('data/3 hours Open Invite 22nd April 2024 Robotics.xlsx', sheet_name=0))\n",
    "dataSets.append(pd.read_excel('data/3 hours Open Invite 22nd April 2024 Robotics.xlsx', sheet_name=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-WDwk4LqgZ5"
   },
   "source": [
    "#### Getting all Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y48M85pwqicf"
   },
   "outputs": [],
   "source": [
    "cols = []\n",
    "for dataSet in dataSets:\n",
    "  cols.extend(dataSet.columns.str.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0o7STLnsgGg"
   },
   "source": [
    "###### Removing Trash Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YDHfD-LGsfUu"
   },
   "outputs": [],
   "source": [
    "cols2 = list(cols)\n",
    "for X in cols:\n",
    "  if 'unnamed' in X.lower(): cols2.remove(X)\n",
    "  if 'column' in X.lower(): cols2.remove(X)\n",
    "\n",
    "cols = list(cols2)\n",
    "\n",
    "ignore = [\n",
    "    'timestamp',\n",
    "    'response type',\n",
    "    'start date (utc)',\n",
    "    'stage date (utc)',\n",
    "    'submit date (utc)',\n",
    "    'network id',\n",
    "    'tags'\n",
    "    ]\n",
    "for X in ignore:\n",
    "  cols.remove(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25FBtzRUssP1"
   },
   "source": [
    "###### Removing Duplicate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2XvDwJ2fsnKa"
   },
   "outputs": [],
   "source": [
    "cols2 = []\n",
    "for X in cols:\n",
    "  if not InList(X, cols2):\n",
    "    cols2.append(X.lower())\n",
    "cols = cols2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYwL8evFvryo"
   },
   "source": [
    "###### All columns to markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2HTExp8LvkL7"
   },
   "outputs": [],
   "source": [
    "# with open('Columns.md', 'w') as file:\n",
    "#   text = ''\n",
    "#   for ind in range(len(cols)):\n",
    "#     text += '\\n'\n",
    "#     text += f'{ind+1}. '\n",
    "#     text += cols[ind].lstrip()\n",
    "#   file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YB5tJC0jUFU9"
   },
   "source": [
    "#### Making Master DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLP Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "classifier = pipeline(\n",
    "    task = 'zero-shot-classification',\n",
    "    model='facebook/bart-large-mnli'\n",
    ")\n",
    "\n",
    "qa = pipeline(\n",
    "    task='question-answering',\n",
    "    model='deepset/roberta-base-squad2'\n",
    ")\n",
    "\n",
    "summarizer = pipeline(\n",
    "    task='summarization',\n",
    "    model = 'facebook/bart-large-cnn'\n",
    ")\n",
    "\n",
    "def experience(text) -> tuple:\n",
    "    labels = ['Experienced', 'Unexperienced']\n",
    "    res = classifier(text, candidate_labels=labels)\n",
    "    # verdict, score = res['labels'][0], res['scores'][0]\n",
    "    op = dict(zip(res['labels'], res['scores']))['Experienced']\n",
    "    # ops = []\n",
    "    # for d in res:\n",
    "    #     ops.append(dict(zip(d['labels'], d['scores']))['Experienced'])\n",
    "    return op\n",
    "\n",
    "def interest(text: str) -> float:\n",
    "    labels = ['Super Interested!', 'Uninterested']\n",
    "    res = classifier(text, candidate_labels=labels)\n",
    "    op = dict(zip(res['labels'], res['scores']))['Super Interested!']\n",
    "    return op\n",
    "\n",
    "def highlightFactor(text):\n",
    "    res = summarizer(\n",
    "        text,\n",
    "        min_length=2,\n",
    "        max_length=4\n",
    "    )\n",
    "    return res\n",
    "\n",
    "def satisfaction(text: str) -> float:\n",
    "    labels = ['Satisfied!', 'Unsatisfied!']\n",
    "    res = classifier(text, candidate_labels=labels)\n",
    "    op = []\n",
    "    for d in res:\n",
    "        op.append(dict(zip(d['labels'], d['scores']))['Satisfied!'])\n",
    "    return op\n",
    "\n",
    "def suggestions(text: str):\n",
    "    res = qa(\n",
    "        question='What are people\\'s opinions or problems with the workshop?',\n",
    "        context=text,\n",
    "        min_tokens = 20\n",
    "    )\n",
    "    return res['answer']\n",
    "\n",
    "def expectation(text: str):\n",
    "    res = qa(\n",
    "        question='What are the main expectations of the speaker from the workshop?',\n",
    "        context=text,\n",
    "        min_tokens = 20\n",
    "    )\n",
    "    return res['answer']\n",
    "\n",
    "def knowledgeGained(text: str) -> float:\n",
    "    labels = ['has learned a lot', 'has learned nothing']\n",
    "    res = classifier(f'after the robotics workshop, {text}', candidate_labels=labels)\n",
    "    op = dict(zip(res['labels'], res['scores']))['has learned a lot']\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950044751167297"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interest('When asked, \"Do you like robotics\", I said, \"YESSSSSS\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DB of Questions and Interpreted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllExperienceColumns = [\n",
    "'what comes to your mind when you hear the word \"robots\" or robotics\"?',\n",
    "'have you attended a robotics workshop before?',\n",
    "'how interested are you in attending this workshop at the american center?',\n",
    "'have you attended a robotics workshop before?',\n",
    "'what is your understanding of robots?'\n",
    "'have you done a simple circuit?',\n",
    "'do you know anything about arduino boards?',\n",
    "'what do you know about robotics?',\n",
    "'what do you know about robotics ? (basics, sensors & actuators, arduino, motor controls)',\n",
    "'what do you know about computer programming/coding/block coding?',\n",
    "'do you have any experience with coding?',\n",
    "'have you attended a robotics program or workshop before ?',\n",
    "' have you worked with simple circuits ?',\n",
    "' do you know anything about microcontrollers arduino & raspberry pi?',\n",
    "' what do you know about robotics ? ( basics , sensors & actuators , arduino , motor controls)',\n",
    "' what is your understanding of robots or robotics?']\n",
    "\n",
    "AllInterestBeforeColumns = [\n",
    "    'what comes to your mind when you hear the word \"robots\" or robotics\"?',\n",
    "\t'have you attended a robotics workshop before?',\n",
    "\t'how interested are you in attending this workshop at the american center?',\n",
    "\t'is computer programming/coding/block coding something that interests you?',\n",
    "\t'based on your understanding, is it something you can learn?',\n",
    "\t'if yes , give a brief description. if no would you like to  know about robotics through a workshop', \n",
    "\t'how interested are you in attending this workshop at american center?',\n",
    "\t'is robotics your passion and how will it align with your future goals?'\n",
    "]\n",
    "\n",
    "AllInterestAfterColumns = [\n",
    "    'would you like to join our whatsapp community, where you will get updates about workshops and also learn cool facts about technology?',\n",
    "\t'will you take stem/computer science as your career?',\n",
    "\t'with all this knowledge do you think you will pursue robotics as your career?',\n",
    "\t'what do you think about robotics after being part of the workshop?',\n",
    "\t'after attending this workshop do you think you will pursue robotics as your career?',\n",
    "\t'do you now have an interest to build your robot?'\n",
    "]\n",
    "\n",
    "AllHighlightFactorColumns = [\n",
    "    'what is that one thing that you have learnt from this workshop and will never forget?',\n",
    "\t'what was the best part of the robotics camp for you',\n",
    "\t'what was one new skill or idea you learned during your project that you found most useful or interesting?',\n",
    "\t'what is one thing you\\'ve learned that you will take back with you or that will be useful in your daily life?',\n",
    "\t'can you tell us about your key takeaways?'\n",
    "]\n",
    "\n",
    "AllSatisfactionColumns = [\n",
    "    'on a scale of 10, how would you rate this workshop?',\n",
    "\t'did you feel you had enough help and tools to come up with and build your project idea? what more could we have given you?',\n",
    "\t'did you feel ready for the project part after the first lessons and activities? if not, what basic things could we have taught better?',\n",
    "\t'would you like to join our whatsapp community, where you will get updates about workshops and also learn cool facts about technology?',\n",
    "\t'how was the session overall on a scale of 1-10?',\n",
    "\t'how would you rate the trainers on a scale of 1-10?',\n",
    "\t'how would you rate the trainers?',\n",
    "\t'how was the overall workshop?',\n",
    "\t'on what scale did this workshop satisfy your expectations?',\n",
    "\t'how was your overall workshop experience ?'\n",
    "]\n",
    "\n",
    "AllSuggestionColumns = [\n",
    "\t'what suggestions do you have for the trainers to improve the workshop?',\n",
    "\t'what was the hardest thing in the camp? how could we have made it easier or clearer for you?',\n",
    "\t'the camp was 2 hours each day. was this time right? if it was too short/long please tell us why.',\n",
    "\t'thinking about how each day was set up, what changes would you suggest to make each day\\'s session better?',\n",
    "\t'what is one main suggestion you have to make the robotics camp even better for the next students?',\n",
    "\t'any comments or suggestions you have regarding the workshop or for the trainers?',\n",
    "\t'what suggestions do you have for the trainers?'\n",
    "]\n",
    "\n",
    "AllImprovementColumns = [\n",
    "    'what topics or activities do you think were missing from the camp, or that you wished we spent more time on?',\n",
    "\t'were there any parts of the camp that were confusing, not important, or not fun? please tell us exactly what.',\n",
    "\t'did you feel ready for the project part after the first lessons and activities? if not, what basic things could we have taught better?',\n",
    "\t'what tools or materials (like websites, specific parts, or other equipment) did youwish you had during the camp?',\n",
    "\t'if you told a friend about this camp, what\\'s the main thing you\\'d say we could do better?'\n",
    "    'we\\'d love to hear from you!if you enjoyed the robotics camp, please take a moment to leave a google review. your words help more students and schools discover us!',\n",
    "\t'any comments or suggestions? '\n",
    "]\n",
    "\n",
    "AllExpectationColumns = [\n",
    "    '1. what are your expectations from this workshop?',\n",
    "\t'2. what would you like to learn during this workshop?',\n",
    "\t'3. what do you like to gain from this workshop ?'\n",
    "]\n",
    "\n",
    "AllKnowledgeGainColumns = [\n",
    "    'how is your understanding on basic electronics and block coding after attending the workshop?',\n",
    "\t'can you rate your understanding on sensors & motors?',\n",
    "\t'do you think you can design and build your robot in the future with the knowledge you have gained?',\n",
    "\t'do you think you can design and build your own robot in the future with the knowledge you have gained?',\n",
    "\t'with all this knowledge do you think you will pursue robotics as your career?',\n",
    "\t'can you rate your understanding on sensors?',\n",
    "\t'do you now have an understanding of how robots are made ?',\n",
    "\t'do you think you can design and build your own robot in the future using arduino?',\n",
    "\t'based upon the working principle of a robot give us an example (sense - plan - act)',\n",
    "\t'can you rate your understanding on the basics of robotics ?',\n",
    "\t'can you rate your understanding on sensors & actuators ?'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxgJdN-sUNMG"
   },
   "source": [
    "##### Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1757930259732,
     "user": {
      "displayName": "Teja Meruva",
      "userId": "00989741806545621269"
     },
     "user_tz": -330
    },
    "id": "ZEKRTCWmt_Ca",
    "outputId": "cedea56b-3997-4f81-f2a0-8c60e734e0c6"
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "durations = []\n",
    "modes = []\n",
    "classes = []\n",
    "genders = []\n",
    "workshopNames = []\n",
    "knowledgeGain = []\n",
    "interestsBefore = []\n",
    "interestsAfter = []\n",
    "expectations = []\n",
    "highlights = []\n",
    "satisfactions = []\n",
    "suggestionsToImprove = []\n",
    "expectations = []\n",
    "knowledgeGain = []\n",
    "experiences = []\n",
    "\n",
    "durationsPerDataSet = 2*['1 hour'] + ['10 day'] + 2*['2 day'] + 4*['3 day'] + 4*['3 hour']\n",
    "modePerDataSet = 2*['Online'] + 11*['Offline']\n",
    "workshopNamePerDataSet = \\\n",
    "2*['1 hour Online intro to Robotics workshop-pilot'] + \\\n",
    "['10 day Summercamp Anna library Feedback'] + \\\n",
    "2*['2 Day learning surveys 2024-2025 American center'] + \\\n",
    "4*['3 days  Robotics Trial Workshop -St. Patrick\\'s School 2024'] + \\\n",
    "2*['3 hour 2023-2024 Robotics workshop'] + \\\n",
    "2*['3 hours Open Invite 22nd April 2024 Robotics']\n",
    "\n",
    "\n",
    "\n",
    "for ind in range(len(dataSets)):\n",
    "    namesToAdd = list(dataSets[ind].loc[:, columnLike('name', dataSets[ind].columns)])\n",
    "    count = len(namesToAdd)\n",
    "    names.extend(namesToAdd)\n",
    "\n",
    "    durations.extend([durationsPerDataSet[ind]]*count)\n",
    "    modes.extend([modePerDataSet[ind]]*count)\n",
    "\n",
    "    workshopNames.extend([workshopNamePerDataSet[ind]]*count)\n",
    "\n",
    "    classCol = columnLike('class', dataSets[ind].columns)\n",
    "    if classCol is not None:\n",
    "        classes.extend(list(dataSets[ind][classCol]))\n",
    "    else:\n",
    "        classes.extend([np.nan for _ in range(count)])\n",
    "\n",
    "    genderCol =  columnLike('gender', dataSets[ind].columns)\n",
    "    if genderCol is not None:\n",
    "        genders.extend(list(dataSets[ind][genderCol]))\n",
    "    else:\n",
    "        genders.extend([np.nan for _ in range(count)])\n",
    "\n",
    "\n",
    "    # experienceCols = columnLike(AllExperienceColumns, dataSets[ind].columns, singleOp=False)\n",
    "    # if experienceCols is not None:\n",
    "    #     sset = pd.DataFrame(dataSets[ind].loc[:, experienceCols])\n",
    "    #     for ind in range(len(sset.columns)):\n",
    "    #         sset.iloc[:, ind] =  sset.iloc[:, ind].apply(lambda x: f'When i was asked, \"{list(sset.columns)[ind]}, I said, {x}\"').apply(experience)\n",
    "    #     experiences.extend(list(sset.mean(axis=1)))\n",
    "    # else:\n",
    "    #     experiences.extend([np.nan for _ in range(count)])\n",
    "\n",
    "    # interestBeforeCols = columnLike(AllInterestBeforeColumns, dataSets[ind].columns, singleOp=False)\n",
    "    # if interestBeforeCols is not None:\n",
    "    #     sset = pd.DataFrame(dataSets[ind].loc[:, interestBeforeCols])\n",
    "    #     for ind in range(len(sset.columns)):\n",
    "    #         sset.iloc[:, ind] =  sset.iloc[:, ind].apply(lambda x: f'When i was asked, \"{list(sset.columns)[ind]}, I said, {x}\"').apply(interest)\n",
    "    #     interestsBefore.extend(list(sset.mean(axis=1)))\n",
    "    # else:\n",
    "    #     interestsBefore.extend([np.nan for _ in range(count)])\n",
    "\n",
    "    # interestAfterCols = columnLike(AllInterestAfterColumns, dataSets[ind].columns, singleOp=False)\n",
    "    # if interestAfterCols is not None:\n",
    "    #     sset = pd.DataFrame(dataSets[ind].loc[:, interestAfterCols])\n",
    "    #     for ind in range(len(sset.columns)):\n",
    "    #         sset.iloc[:, ind] =  sset.iloc[:, ind].apply(lambda x: f'When i was asked, \"{list(sset.columns)[ind]}, I said, {x}\"').apply(interest)\n",
    "    #     interestsAfter.extend(list(sset.mean(axis=1)))\n",
    "    # else:\n",
    "    #     interestsAfter.extend([np.nan for _ in range(count)])\n",
    "    \n",
    "    # suggestionsCols = columnLike(AllSuggestionColumns + AllImprovementColumns, dataSets[ind].columns, singleOp=False)\n",
    "    # if suggestionsCols is not None:\n",
    "    #     sset = pd.DataFrame(dataSets[ind].loc[:, suggestionsCols])\n",
    "    #     for ind in range(len(sset.columns)):\n",
    "    #         sset.iloc[:, ind] =  sset.iloc[:, ind].apply(lambda x: f'These are the suggestions I have for improvement: {x}\"').apply(suggestions)\n",
    "    #     # print(sset)\n",
    "    #     combinedSuggestions = pd.Series(['' for _ in range(dataSets[ind].shape[0])])\n",
    "    #     for col in sset.columns:\n",
    "    #         combinedSuggestions += sset[col] + ' '\n",
    "    #     suggestionsToImprove.extend(list(combinedSuggestions))\n",
    "    # else:\n",
    "    #     suggestionsToImprove.extend([np.nan for _ in range(count)])\n",
    "\n",
    "    # highlightCols = columnLike(AllHighlightFactorColumns, dataSets[ind].columns, singleOp=False)\n",
    "    # if highlightCols is not None:\n",
    "    #     sset = pd.DataFrame(dataSets[ind].loc[:, highlightCols])\n",
    "    #     text = pd.Series(['' for _ in range(dataSets[ind].shape[0])])\n",
    "    #     for ind in range(len(sset.columns)):\n",
    "    #         text +=  sset.iloc[:, ind] + ' '\n",
    "    #     #print(text)\n",
    "    #     # results= highlightFactor(list(text))\n",
    "    #     highlights.extend(list(text))\n",
    "    # else:\n",
    "    #     highlights.extend([np.nan for _ in range(count)])\n",
    "\n",
    "    satisfactionCols = columnLike(AllSatisfactionColumns, dataSets[ind].columns, singleOp=False)\n",
    "    if satisfactionCols is not None:\n",
    "        sset = pd.DataFrame(dataSets[ind].loc[:, satisfactionCols])\n",
    "        text = pd.Series(['' for _ in range(dataSets[ind].shape[0])])\n",
    "        for ind in range(len(sset.columns)):\n",
    "            col = list(sset.columns)[ind]\n",
    "            text +=  sset.iloc[:, ind].astype('str').apply(lambda x: f'When I was asked, {col}, I said, {x}. ')\n",
    "    #     print(text)\n",
    "        results= satisfaction(list(text))\n",
    "        satisfactions.extend(list(results))\n",
    "    else:\n",
    "        satisfactions.extend([np.nan for _ in range(count)])\n",
    "\n",
    "    # expectationCols = columnLike(AllExpectationColumns, dataSets[ind].columns, singleOp=False)\n",
    "    # if expectationCols is not None:\n",
    "    #     sset = pd.DataFrame(dataSets[ind].loc[:, expectationCols])\n",
    "    #     for ind in range(len(sset.columns)):\n",
    "    #         sset.iloc[:, ind] =  sset.iloc[:, ind].apply(lambda x: f'These are the expectations I have: {x}\"').apply(expectation)\n",
    "    #     # print(sset)\n",
    "    #     combinedExpectations = pd.Series(['' for _ in range(dataSets[ind].shape[0])])\n",
    "    #     for col in sset.columns:\n",
    "    #         combinedExpectations += sset[col] + ' '\n",
    "    #     expectations.extend(list(combinedExpectations))\n",
    "    # else:\n",
    "    #     expectations.extend([np.nan for _ in range(count)])\n",
    "\n",
    "    # knowledgeGainColumns = columnLike(AllKnowledgeGainColumns, dataSets[ind].columns, singleOp=False)\n",
    "    # if knowledgeGainColumns is not None:\n",
    "    #     sset = pd.DataFrame(dataSets[ind].loc[:, knowledgeGainColumns])\n",
    "    #     for ind in range(len(sset.columns)):\n",
    "    #         sset.iloc[:, ind] =  sset.iloc[:, ind].apply(lambda x: f'When i was asked, \"{list(sset.columns)[ind]}, I said, {x}\"').apply(knowledgeGained)\n",
    "    #     knowledgeGain.extend(list(sset.mean(axis=1)))\n",
    "    # else:\n",
    "    #     knowledgeGain.extend([np.nan for _ in range(count)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['name'] = pd.Series(names)\n",
    "data['gender'] = pd.Series(genders)\n",
    "data['class'] = pd.Series(classes)\n",
    "data['mode'] = pd.Series(modes)\n",
    "data['workshop_name'] = pd.Series(workshopNames)\n",
    "data['workshop_duration'] = pd.Series(durations)\n",
    "data['interest_before'] = pd.Series(interestsBefore)\n",
    "data['interest_after'] = pd.Series(interestsAfter)\n",
    "data['highlights'] = pd.Series(highlights)\n",
    "data['suggestions'] = pd.Series(suggestionsToImprove)\n",
    "data['satisfaction'] = pd.Series(satisfactions)\n",
    "data['expectations'] = pd.Series(expectations)\n",
    "data['prior_experience'] = pd.Series(experiences)\n",
    "data['knowledge_gain'] = pd.Series(knowledgeGain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('satisfaction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(872)"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.knowledge_gain.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOy8NgnumJOC23bqS8RY+LA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
