{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMnzPTkI9Zj1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/CodeBotixMaster.csv')\n",
        "\n",
        "def preprocess_name(name):\n",
        "    if pd.isnull(name):\n",
        "        return \"\"\n",
        "    name = name.lower().strip()\n",
        "    name = name.replace('.', ' ')\n",
        "    name = re.sub(r'[^a-z\\s\\'-]', '', name)\n",
        "    tokens = name.split()\n",
        "    if len(tokens) == 0:\n",
        "        return \"\"\n",
        "\n",
        "    index = 0\n",
        "    while index < len(tokens) and len(tokens[index]) == 1:\n",
        "        index += 1\n",
        "    if index < len(tokens):\n",
        "        return tokens[index]\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "df['first_name'] = df['name'].apply(preprocess_name)"
      ],
      "metadata": {
        "id": "BPkNVwI_9ewj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/Gender_Data.csv')\n",
        "\n",
        "train_df['Name'] = train_df['Name'].astype(str).str.lower().str.strip()\n"
      ],
      "metadata": {
        "id": "UDY8r4dCHq8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = set(\"\".join(train_df['Name']))\n",
        "char2idx = {c: i+1 for i, c in enumerate(sorted(chars))}\n",
        "idx2char = {i: c for c, i in char2idx.items()}\n",
        "vocab_size = len(char2idx) + 1\n",
        "\n",
        "def encode_name(name, max_len):\n",
        "    seq = [char2idx.get(c, 0) for c in name]\n",
        "    if len(seq) < max_len:\n",
        "        seq += [0] * (max_len - len(seq))\n",
        "    else:\n",
        "        seq = seq[:max_len]\n",
        "    return seq\n",
        "\n",
        "max_len = max(len(n) for n in train_df['Name'])\n",
        "X = np.array([encode_name(n, max_len) for n in train_df['Name']])\n",
        "y = train_df['Gender'].values"
      ],
      "metadata": {
        "id": "VRIHjn8RLplE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "cye2LhdoMOgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = NameDataset(X, y)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=256)"
      ],
      "metadata": {
        "id": "WpFqvn_xMP8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        out = self.fc(h_n[-1])\n",
        "        return self.sigmoid(out).squeeze()"
      ],
      "metadata": {
        "id": "UDfvvN0uM5gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LSTMClassifier(vocab_size, embed_dim=64, hidden_dim=128).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "SvnDU_YIM5cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, total_correct, total_samples = 0, 0, 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(X_batch)\n",
        "            loss = criterion(preds, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(y_batch)\n",
        "            total_correct += ((preds > 0.5).int() == y_batch.int()).sum().item()\n",
        "            total_samples += len(y_batch)\n",
        "\n",
        "        train_acc = total_correct / total_samples\n",
        "        val_acc, val_loss = evaluate(model, val_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {total_loss/total_samples:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_correct, total_samples = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            preds = model(X_batch)\n",
        "            loss = criterion(preds, y_batch)\n",
        "            total_loss += loss.item() * len(y_batch)\n",
        "            total_correct += ((preds > 0.5).int() == y_batch.int()).sum().item()\n",
        "            total_samples += len(y_batch)\n",
        "    return total_correct / total_samples, total_loss / total_samples"
      ],
      "metadata": {
        "id": "QaBqom-YNWrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cAAqCrdNc40",
        "outputId": "bc9d3f01-1b50-46c5-94fb-6d0062e92210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train Loss: 0.1512, Train Acc: 0.9463, Val Loss: 0.1889, Val Acc: 0.9323\n",
            "Epoch 2/5 | Train Loss: 0.1456, Train Acc: 0.9495, Val Loss: 0.1977, Val Acc: 0.9292\n",
            "Epoch 3/5 | Train Loss: 0.1442, Train Acc: 0.9501, Val Loss: 0.1910, Val Acc: 0.9322\n",
            "Epoch 4/5 | Train Loss: 0.1371, Train Acc: 0.9531, Val Loss: 0.1965, Val Acc: 0.9277\n",
            "Epoch 5/5 | Train Loss: 0.1324, Train Acc: 0.9544, Val Loss: 0.2019, Val Acc: 0.9287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_gender(new_df, model, max_len, char2idx):\n",
        "    new_df['Name'] = new_df['Name'].astype(str).str.lower().str.strip()\n",
        "    X_new = np.array([encode_name(n, max_len) for n in new_df['Name']])\n",
        "    X_new = torch.tensor(X_new, dtype=torch.long).to(device)\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_new).cpu().numpy()\n",
        "    new_df['Predicted_Gender'] = (preds > 0.5).astype(int)\n",
        "    return new_df"
      ],
      "metadata": {
        "id": "I8I7q8tJRPhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['gender'].value_counts(dropna=False))\n",
        "\n",
        "mask_missing = df['gender'].isna()\n",
        "missing_names = df.loc[mask_missing, 'first_name']\n",
        "\n",
        "predicted_df = predict_gender(\n",
        "    pd.DataFrame({\"Name\": missing_names}),\n",
        "    model, max_len, char2idx\n",
        ")\n",
        "\n",
        "df.loc[mask_missing, 'gender'] = predicted_df['Predicted_Gender']\n",
        "\n",
        "print(df['gender'].value_counts())\n",
        "\n"
      ],
      "metadata": {
        "id": "BOklFDcdRY97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['gender'] = df['gender'].replace({0: \"male\", 1: \"female\"})\n",
        "df['gender'] = df['gender'].replace({0: \"male\", 1: \"female\"})"
      ],
      "metadata": {
        "id": "pgwJoVrSVxcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "j0YIdppyTi9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXii2OAPTXt5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}